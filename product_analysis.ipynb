{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming for Data Analyis Project Semester 2 ( 2020)\n",
    "Brendan Ryan GMIT Student"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Notebook Index:  </b>\n",
    "\n",
    "In this Jupyter notebook I will give an overview of the following \n",
    "\n",
    "-  <a href='#project_overview'>1. Project Overview</a>\n",
    "    - <a href='#the_task'> The Task</a>\n",
    "    - <a href='#project_aims'> Project Aims and the Phenomenon\"</a>\n",
    "- <a href='#getting_started'> 2. External Research\"</a> \n",
    "- <a href='#getting_started'> 3. Getting Started - How did i obtain my data\"</a>\n",
    "    - <a href='#import_lib'>Importing Required Libraries</a>\n",
    "    - <a href='#import_data'> Importing the Data</a>\n",
    "    - <a href='#analyse'> Analyse and Reviewing the Data</a>\n",
    "    - <a href='#distributions'> Types of distributions</a>\n",
    "    - <a href='#age_dist'> Analyse Age Data and Distribution</a>\n",
    "    - <a href='#amount_dist'> Analyse Loan Amount Data and Distribution</a>\n",
    "    - <a href='#loan_purpose_dist'> Analyse Loan Purpose Data and Distribution</a>\n",
    "    - <a href='#gender_dist'> Analyse Gender Data and Distribution</a>\n",
    "- <a href='#relationships'>4. Visualise Some of the Relationships between Variables</a>\n",
    "    - <a href='#corr'>Correlation between Numerical Variables</a>\n",
    "    - <a href='#freq'>Frequency Table</a>\n",
    "- <a href='#simulated_data'>5.  Create simulated synthetic random</a>\n",
    "- <a href='#predictions'>6.  Using our Data to make Predictions</a>\n",
    "- <a href='#conclusion'>7.  Project Conculsion and Summary</a>\n",
    "- <a href='#research'>8. Research Undertaken and Sources</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='project_overview'></a>\n",
    "## Project Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The repository for this assignment and the README in relation to this jupyter notebook are located at\n",
    "- https://github.com/brendantipp/sem2_prog_data_analysis_project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='the_task'></a>\n",
    "#### The Task\n",
    "Project task to create a sythesised Dataset simulating a real world phenomenon.\n",
    "\n",
    "For this project I have picked a real world phenomenon that exists in my own professional worplace which is a credit union.\n",
    "\n",
    "That is what  is the likelyhood of a member of the financial institution I work in availing of a service (in this case avail of a loan), based on variables that are contained in a pre existing database - for my project I will look at the variables listed below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- AGE\n",
    "- Month (month of application)\n",
    "- Date (date of appliation)\n",
    "- Employment Status\n",
    "- Gender\n",
    "- Loan Type\n",
    "- Loan Amount Range\n",
    "- Loan Amount\n",
    "\n",
    "\n",
    "My main aim is to be able to determine the particular loan type that will be availabe of by Age and Gender."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='project_aims'></a>\n",
    "#### Project Aims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this project is to extract and analyise a real world phenomenon which is lending by age profile and from this try and determine the probabilites of loan products by age group and gender.\n",
    "\n",
    "I will do this analysis using Python code through a jupyter notebook and utilising various additional libraries will review and analise my dataset. \n",
    "\n",
    "In particular I want to look for any relationships between the variables and their likely distributions. \n",
    "\n",
    "From this research I then aim to create a synthetic simulated data set that will match as closely to my real world dataset. This simulated dataset could then be used for further testing and with a view to making predictions etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='getting_started'></a>\n",
    "#### Getting Started - How did i obtain the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I obtained the data from an internal system using Business Intellegince software. That software that was used was Pentago BI. \n",
    "I extracted the data I felt I needed (the varibales) and this data was extracted/exported to a csv file. This was ideal as phython and pandas is widely used to analysise data contained in the CSV file format. The CSV file is saved in my repository as analysis.csv. This csv does not contain any presonal information and is used more for identifying trends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='external_research'></a> \n",
    "## External Research of borrowing by Age profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The majority of my analysis will be based around the data that i have extracted i.e the real life data. There is a wealth of data availabel online however i felt most of this data related more to the mortage market and outstanding debit where i am more interested in this particular project to look at new borrowing and the profile of same. However i feel that with this course and futher reading and experimenting i will do a project on loans outstading by difference demographics etc and analysise trends over a number of years. I will however include the following as i found them interesting and i will quote external sources in some of my findings as we analise the data further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the graph below which shows the number of products held by age profile in a sample financial instituion. It is intersting to note here that number of products held (including loans) starts to rise sharply from age 30 - peaking in the age group 45 - 54 and then delcining from age 55 onwards - it will be interesting to see if this is similar ot the patter or loans applied for by age groups in my dataset. - source https://www.cso.ie/en/releasesandpublications/ep/p-hfcs/householdfinanceandconsumptionsurvey2018/debtandcredit/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/image1.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again in the next graph we can see the Distribution of average debt from personal loans* in the United Kingdom (UK) 2017, by age profile - although this graph looks at the debt outstanding it also gives usa nother indication as to the age profile of peronal lending. - https://www.statista.com/statistics/793646/average-amount-owed-in-loans-uk/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/image2.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the graph above the main age mean is approx 40 years old increasing from age 25 upwards and declinning again from age 45 onwards - I would expect to see this follow through in the analysis of my own data set  -lets see"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='import_lib'></a>\n",
    "## Getting Started - importing required libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required libraries\n",
    "I will be using the numpy.random package from python and i will also be utilising the Matplotib and Seaborn packages for better visualisation using graphs. Futher on in the project i will look at tools availble from Sklearn and Scipy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to import pandas is a software library for data manipulation and analysis\n",
    "import pandas as pd\n",
    "#code to import numpy for working with arrays scientific computer etc \n",
    "import numpy as np\n",
    "#code to import matplotlib plotting library\n",
    "import matplotlib.pyplot as plt\n",
    "#code to import seaborn - more plots better visual\n",
    "import seaborn as sns\n",
    "#magic code to show plots as required \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='importing_dat'></a>\n",
    "#### Importing the Data\n",
    "Import our Data Set based on the output of ones years lending - we are going to use Pandas library to read and for analysing our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import my dataset and best practice name as df\n",
    "df = pd.read_csv('analysis.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='analyse'></a>\n",
    "#### Test that our data set has loaded and check for errors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n",
    "# I can if i want if its a large dataset only return lets say 100 rows ** come back to this "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok from above we can determine we have 3936 rows of date with 8 colums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### df.head and df.tail\n",
    "Now lets further analyse and examine our imported data by using df.head and df.tail functions that are available in pandas.\n",
    "\n",
    "Firstly df.head() function returns the first 5 rows (default) -  both functions are useful for quickly testing if our dataset has the right type of data in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas df.head fucntion default is to return 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pands df.tail function by default reuturns last 5 rows \n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything looks ok above we can see the shape of our dataframe is correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a look at the typoe of varibables we have to work with using the df.dtypes function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using pandas df.types to looking at the data types \n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok as we can see from above we are dealing with 3 different data types - \n",
    "- int64 for age\n",
    "- object for the variables month_application,date_application, employment_status,gender,loan_purpose, loan_amount_range\n",
    "- float64 for the loan_amount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the above results we can assertain that we need to covert the date of application to a date_time type rather than an object which it currently is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at making the Financial month a date time # help from https://https://pbpython.com/pandas_dtypes.html\n",
    "#https://stackoverflow.com/questions/16852911/how-do-i-convert-dates-in-a-pandas-data-frame-to-a-date-data-type\n",
    "df[\"new_date_application\"]= pd.to_datetime(df['date_application'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### df.info()\n",
    "Lets have a look at df.info which is another useful tool to give us more info on our dataframe and to check has our to date time  above worked. I will leave both the date_application and the new_date_application in my data frame to show the differnce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using pandas built in function df.info to us more info including each data type in use\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above we have a colum new_date_application which is dytpe of datetime64[ns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using pands df.describe to give us more statistical info\n",
    "df.describe().round(decimals = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok as Age and Loan Amount are our only columns of type integer/floating points they are the only ones which will be returned for statistical values as shown above.\n",
    "\n",
    "So using the pandas df.desribe function we get some insteresting statistics for the age and the loan amounts,\n",
    "The average age of our borower is 45 years old, this corresponds with out reasearch above which showed the average age of a borrower as approx 40 years to 45 years. We can determine the average loan amount is approx €4,756. \n",
    "We will cross check these stats further on in our sythentic data set to make sure they align and to ensure our sythentic dataset is a valid represenation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best practice convert some of our data types into categories\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html\n",
    "\n",
    "The Pandas documentation has a consise section on when to use the categorical data type and they recommend it should be use the following data type:\n",
    "\n",
    "\n",
    "\n",
    "- A string variable consisting of only a few different values. Converting such a string variable to a categorical variable will save some memory, see here.\n",
    "\n",
    "- The lexical order of a variable is not the same as the logical order (“one”, “two”, “three”). By converting to a categorical and specifying an order on the categories, sorting and min/max will use the logical order instead of the lexical order, see here.\n",
    "\n",
    "- As a signal to other Python libraries that this column should be treated as a categorical variable (e.g. to use suitable statistical methods or plot types)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert required varibales to cateogories\n",
    "df[[\"month_application\",\"gender\", \"employment_status\",\"loan_purpose\"]] = df[[\"month_application\",\"gender\", \"employment_status\",\"loan_purpose\"]].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using pandas built in function df.info to us more info including each data type in use\n",
    "df.info();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok as we can see from above by changing some of our data types from objects to categoires the memory ussag has almost halfed from 246 kb to 149kb - this may not mean alot for this dataset but if we want to analyse a number of years data or other large datasets the efficiency in memory usage would be very benefiical and result in our code running faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add additional numerical value data by coverting month of application into a number \n",
    "\n",
    "As the project progressed i noticed that for ease of generating random data, looking at the stats of this random data and for the relationships that I required more numerical data. Figuring out the correlation between variables was also only possible using numberical values. It was for that reason I decied to covered my month of application data to numerical.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate a month number for each month of application\n",
    "df['month_number'] = pd.DatetimeIndex(df['new_date_application']).month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='distributions'></a>\n",
    "## Reviewing the data to figure out the types of distributions\n",
    "\n",
    "The main aim in this analysis is to look at the distribution of the age and gender data then look at the relationship between the age and gender of the borrower against the loan pupose and then investigate the relationship between the loan pupose and the amount amount borrowed. We will then use our findings to help create a synthetic data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='age_dist'></a>\n",
    "### Analyse Age data and Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using pandas.describe function to return stats and .round to round values for presentation\n",
    "df.age.describe().round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#declare the variable age - can call directly from dataframe also! will use further on\n",
    "age = df[\"age\"]\n",
    "#use a displot from seaborn for visualisation \n",
    "sns.distplot(age);\n",
    "#give the plot a title \n",
    "plt.title(\"Distribution of Age\")\n",
    "#show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from using df.describe and visualised using our plot the average age of the borrower is 45 - the minimum age is 19 and the max age of a borrower is 89. \n",
    "\n",
    "Based on the above and after much research i have have decided that our age distribution matches closest to that of a Triangular Disbtribution and i will discuss that futher below when creating my sample Age data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='amount_dist'></a>\n",
    "### Analysis Loan Amount Data and Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform a pandas df.desribe for stats on loan_amount\n",
    "df.loan_amount.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a seaborn displot to visualise the distribution\n",
    "sns.distplot(df[\"loan_amount\"]);\n",
    "plt.title(\"Distribution of Loan Amount\")\n",
    "#give the plot a title\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My research pointed me towards a pareto distribution or a Exponential Distirbution  but i found it quiet difficult to code random sample data based on these distributions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='loan_purpose_dist'></a>\n",
    "### Analyse Loan Purpose Data and Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To analyse my loan_puopose column in my dataframe i am going to use a category plot from seaborn. This is a nice visual plot and by using the kind = count will count the number of times each value is found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"loan_purpose\", kind=\"count\", palette=\"ch:.25\", data=df);\n",
    "#Give the plot a title \n",
    "plt.title(\"Count of Loans by Purpose\")\n",
    "#https://seaborn.pydata.org/tutorial/categorical.html\n",
    "#show the plot \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see above that ther are 5 possible outcomes for the loan puporse. I feel that the best way to generate the random sample data from above would be to use the Numpy choice function to generate the sample data based on probabilities which we will exmplore further on. A normal distribution or maybe a triangular distribition is the closeset match but i will use the choice function using probabilites to create random sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Analyse Employment status if required\n",
    "## sns.catplot(x=\"employment_status\", kind=\"count\", palette=\"ch:.25\", data=df);\n",
    "#https://seaborn.pydata.org/tutorial/categorical.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='gender_dist'></a>\n",
    "### Analyse Gender Data and Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To analyse the distribution of gender we can firstly use the Pandas function goupby and count to return the nuber of values for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the groby and count functions to count the number of males and females\n",
    "df[[\"gender\",\"age\"]].groupby(\"gender\").count()\n",
    "#https://pandas.pydata.org/pandas-docs/dev/getting_started/intro_tutorials/06_calculate_statistics.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from above that in our dataset there are slightly more female that male borrowing members."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use a Seaborn Count plot to visualise our values - a countplot is essentially the same as barplot except the estimator is explicitly counting the number of occurrences. Which is why we only pass the x value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seaborn countplot using gender colum from dataset\n",
    "sns.countplot(x='gender',data=df);\n",
    "#https://datascienceplus.com/seaborn-categorical-plots-in-python/\n",
    "#give the plot a title\n",
    "plt.title(\"Loan Counts by Gender Profile\")\n",
    "#show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot above and our stats we can see that the distribution can be classed as a uniform distribution. We will use this distribution further on when creating our random sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Analyse Month of Application Data and Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a seabron countplot of month number\n",
    "sns.countplot(data=df, x = \"month_number\");\n",
    "#give the plot a title\n",
    "plt.title (\"Number of loans by Month Number\")\n",
    "#shot the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above I think a uniform distribution would best match my sample data. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='relationships'></a>\n",
    "### Visualise Some of the Relationships between Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to look at some of the relationships between some of the the variables. This can be done by utilising a number of graphs and plots available within python libraries. I will also take a look at the correlatioin between some of the varibales using the tools availabel from Numpy and possibly from Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relationship betwen Age and Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using seaborn boxplot with x and y variables to visuale relationship between age and gender\n",
    "sns.boxplot(x='gender',y=\"age\",data=df);\n",
    "#give the plot a title\n",
    "plt.title(\"Relationship between Age and Gender\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from above that the breakdown of gender by age group that it is quiet similar with the main concetration in the 30 to 60 age group for both males and females - we will test our sample generated further to see can we get it to match as close to above as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loan Purpose by Age and Gender Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using seaborn boxplot with x and y variables to visuale relationship between age and loan purpose\n",
    "sns.catplot(x=\"loan_purpose\", y=\"age\", hue=\"gender\", kind=\"box\", data=df); #https://seaborn.pydata.org/tutorial/categorical.html\n",
    "#give the plot a title\n",
    "plt.title(\"Loan Purpose by Age and Gender Box Plot\")\n",
    "#show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above this catplot from seaborn shows a very nice visual represenation between the loan pupose selcted by the borrower based on their age and gender. \n",
    "Some interesting points to take from this \n",
    "mthe breakdown is very much 50/50 between teh loan purpose selected for both females and males expect for \n",
    "- Agri prupose where we can now determine it is predominenlty males aged between 40 and 58 - which is probably no suprise\n",
    "- Suprisingly for me More males tend to take studeent loans than females - however it is quiet evident that student loans as we would expect are taken by members aged in thh 20 to 35 age group with the average approx 22/23 year old\n",
    "- Apart from Student loans the average age of borrowers is approx between 38 and 50 in most cases. This stat would also suggests that this is the main catchemnt group and possibly younger members are either not borrowing or borrowing elsewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, (ax1,ax2) = plt.subplots(ncols = 2, sharey=True)\n",
    "#sns.catplot(x=\"gender\", y=\"age\", hue=\"loan_purpose\", kind=\"bar\", data=df);\n",
    "#sns.countplot(x='loan_purpose',hue=\"gender\" , data=df, ax = ax1);\n",
    "#sns.countplot(x='loan_purpose',hue=\"gender\" , data=df, ax = ax2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##using seaborn boxplot using x y varibaes and using loan purpoose as the \"hue\" for visualisation\n",
    "sns.catplot(x=\"gender\", y=\"age\", hue=\"loan_purpose\", kind=\"bar\", data=df);\n",
    "#give the plot a title\n",
    "plt.title(\"Loan Purpose by Age and Gender\")\n",
    "#show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is also another very good visulation of the loan pupose is gender is most likely to borrwer for and the average age these borrowers. We can see again based on the use of the black line the average age of the borrower per loan purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the style of the countplot\n",
    "sns.set(style=\"darkgrid\")\n",
    "#generate a countplot of loan purpose\n",
    "sns.countplot(x='loan_purpose',hue=\"gender\" , data=df)\n",
    "#show the title\n",
    "plt.title (\"Loan Purpose by Gender Profile\")\n",
    "#plot the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/hands-on-python-data-visualization-seaborn-count-plot-90e823599012"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above countplot from the seaborn library shows the breakdown of loan pupose by gender. It is a good visulisation to see the product (loan pupose) each gender decides upon. Observations - more males borrow for cars, studnet and agir  loans however females tend to borrow more for Home and Personal purposes and these are the most popular loan purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loan Purpose by Month of Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here i will look at the loan application pupoose by the month of the application. I have already covereted the month of application to a number and I will use this field. I could also use the Month of applicatioin field if i wished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))#used to extend size of grapch for better visual\n",
    "#display using a seaborn countplot\n",
    "plt.title(\"Loan Purpose by Month of Application\")\n",
    "#create a count plot for the month number and loan purpose\n",
    "sns.countplot(x='month_number',hue=\"loan_purpose\" , data=df);\n",
    "#display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above graph give us some very interesting insights into the data for the loan purpose by the month of application.\n",
    "\n",
    "- The number personal loans is consistent through the year with a spike in November suggesting more personal loan applications in the lead up to christas\n",
    "- The number of Student loans is at its highest around August with teh second highest month of applications being September, this would suggest the majority of students/parents will be looking at their school or 3rd level expenses at this time which is to be expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seaborn library has a great heat map visual tool that can be used to map the correlations between categories. The higher the number is the greater the correlation between the two elements. A high positive corrleation indicates that the two elements have a positive linear relationship (as one increases the other also increase), and a low negative correlation indicates a negative linear relationship( as one increases the other decreases)\n",
    "\n",
    "link reference to medium here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='corr'></a>\n",
    "### Correlation between Numerical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr(),annot= True); #insert link here from medium that i used from below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We  can also calculate the correlation between any two variables by using the code below however i found the visul heatmap above a great way of displaying the results. Below can also be achived in pands using df.corr but as the basis of this project is numpy i will use np.corrcoef in  my example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = np.corrcoef(df['age'],df[\"loan_amount\"],)\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='freq'></a>\n",
    "### Frequency Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my research i found the following very interesting which is a method of finding the distribution between two categorial variables - reference - https://www.pluralsight.com/guides/finding-relationships-data-with-python\n",
    "A crosstab function can be used to create a  two way table between two variables - below i will create a two way table between the categorical varibales loan_purpose and gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the pandas crosstab function\n",
    "#pd.crosstab(df[\"loan_purpose\"],df[\"gender\"])\n",
    "pd.crosstab(df[\"loan_purpose\"],df[\"employment_status\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualising some relationships using a Pairplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df,hue =\"gender\");\n",
    "#show the title\n",
    "plt.suptitle(\"Original Data Pairplot\");\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the seaborn pairplot - set the due to loan purpose for better visualisation \n",
    "sns.pairplot(df,hue =\"loan_purpose\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='simulated_data'></a>\n",
    "## Create Simulated Synthetic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is synthetic data?\n",
    "\n",
    "Synthetic data is artificial data that is created by using different algorithms that mirror the statistical properties of the original data but does not reveal any information regarding real people\n",
    "\n",
    "#### Why is synthetic data important for businesses?\n",
    "Synthetic data is important for businesses due to three reasons: privacy, product testing and training machine learning algorithms.\n",
    "\n",
    "#### When to use synthetic data?\n",
    "\n",
    "Businesses trade-off between data privacy and data utility while selecting a privacy-enhancing technology. Therefore businesses need to determine the priorities of their use case before investing. Synthetic does not contain any personal information, it is a sample data that has a similar distribution with original data. However, the utility of synthetic data can be lower than real data.\n",
    "\n",
    "source https://research.aimultiple.com/synthetic-data-generation/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My Synthesised Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am now going to simulate a new sample dataset matching as closely as possible to the imported dataset above which i have analysed.\n",
    "\n",
    "My new sample dataset will have x number of colums containing 4,000 rows of data. (I have picked 4,000 so it will be closey to my original dataset)\n",
    "\n",
    "The new colums I have selected for my sample data set will be as follows as the main purpose was to see the relationships betwen these 4 variables.\n",
    "\n",
    "- sample_age\n",
    "- sample_loan_purpose\n",
    "- sample_gender\n",
    "- sample_loan_amounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below i am going to create an empty dataframe and set the numper of samples to use for this project. The project example was 200 data points but as i want to match as closely as possibly to my original dataset I will create 3996 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create emplty data frame in pandas\n",
    "sample_df = pd.DataFrame()\n",
    "#set/define our number of samples\n",
    "n_samples = 3936"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Initialize np.random.default_rng()\n",
    "\n",
    "Best practice in Numpy v1.19 is to use Random Generator. The Generator provides access to a wide range of distributions, and served as a replacement for RandomState. The function numpy.random.default_rng will instantiate a Generator with numpy’s default BitGenerator as shown below. reference - https://numpy.org/devdocs/reference/random/generator.html#numpy.random.default_rng\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function numpy.random.default_rng will instantiate a Generator with numpy’s default BitGenerator.\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Sample Age Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with the creation of the sample data as per the Age column - as i said above i believe the distribtion of the Age variable is closest aligned to that of a Triangular Distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to use the pands df.describe fuction to get the mean and standard deviation of the data in the Age column and we will incorporate this into our numpy triangular distribution function to create our sample data. I wanted to use a distribution where i could define my mix and max ageas and also use the meean from my imported dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using pandas .describe fucntion on our age column.\n",
    "df.age.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from above result we can set our mean_age and deviation_age\n",
    "mean_age = 45.24\n",
    "#we will also set our min age and max age\n",
    "min_age, max_age = 19,89"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numpy.random.triangular fucntion is as follows - ref numpy.org\n",
    "numpy.random.triangular(left, mode, right, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the column random_age using numpys random distribution t - covert to integer\n",
    "sample_age = rng.triangular(min_age,mean_age,max_age,n_samples).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use seaborns displot to visulise results \n",
    "sns.distplot(sample_age);\n",
    "sns.distplot(age);\n",
    "plt.title(\"Original Age Data v Sample Age Data\")\n",
    "plt.show()\n",
    "print(\"The Sample Mean Age is\", sample_age.mean().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am happy that i have been able to set the min and max age and that my average is approx 50 - it is not 100% correct and higher than my original mean age but as this is used for sample data i will run with this. I am happy with the distribution as visualised above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Sample Loan Purpose Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have already coverted the date in loan purpose to a category as I am aware there are not that many unique values and that type of date is ideal for as data type category.  \n",
    "\n",
    "I am going to create a new list from the unique values in my column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new list sample loan types from unique values in loan_purpose from my dataframe\n",
    "sample_loan_types = df['loan_purpose'].unique().tolist()\n",
    "#https://cmdlinetips.com/2018/01/how-to-get-unique-values-from-a-column-in-pandas-data-frame/\n",
    "sample_loan_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So from above I  know there are 5 unique loan purposes and i have created a new list sample_loan_types which contains these values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Setting my probabilities "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I found useful information as reference below on how to covert my loan_pupose counts into a dict. \n",
    "The key being returnend in the Dict is the loan purpose and we can see that it returns the calculated perecentate as a fraction being the number of times each appeared for example below we can see that borrowers opted for a personal loan in over 50% of cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.value_counts.html\n",
    "#https://stackoverflow.com/questions/29403192/convert-series-returned-by-pandas-series-value-counts-to-a-dictionary\n",
    "org_loan_types_prob =dict(df['loan_purpose'].value_counts(True).round(2))\n",
    "print(\"Orginal calc prob /\" ,org_loan_types_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to use the values returned above to set our probabilites our random.choice function. I had to be careful to match teh proabilites to teh values exaclty as how they appeared in the list sample_loan_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create our random loan data using random.choice and the proababilities\n",
    "#0.176829,0.044970,0.501270,0.265498,0.011433\n",
    "sample_loan_purpose = rng.choice(sample_loan_types, size=n_samples,p=[0.176829,0.044970,0.501270,0.265498,0.011433])\n",
    "#create a test dataframe dftest\n",
    "dftest = pd.DataFrame({'sample_loan_purpose':sample_loan_purpose})\n",
    "#create a new dict from above to test values returned against original \n",
    "probabilty_test =dict(dftest['sample_loan_purpose'].value_counts(True).round(2))\n",
    "print(\"Sample calc probabilites /\",probabilty_test)\n",
    "print(\"Orginal calc prob /\" ,org_loan_types_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok so we can see from the above the proability of the loan purpose appearing in our sample dataset is closely aligned to the probability of that in our new sample random data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Sample Gender Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_values = (\"Male\", \"Female\")\n",
    "sample_gender = rng.choice(gender_values,size = n_samples,p = [.45,.55])\n",
    "\n",
    "#Random_Gender.describe\n",
    "#Random_Gender\n",
    "\n",
    "sns.countplot(sample_gender)\n",
    "plt.title(\"Sample Gender Data\");\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Sample Loan amounts data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_loan_amounts_prob =dict(df['loan_amount'].value_counts(True))\n",
    "#sample_loan_amounts_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there must be a random choices in Numpy not just from standard libruary?\n",
    "#https://stackoverflow.com/questions/4859292/how-to-get-a-random-value-from-dictionary-in-python\n",
    "#https://stackoverflow.com/questions/40927221/how-to-choose-keys-from-a-python-dictionary-based-on-weighted-probability\n",
    "import random\n",
    "sample_loan_amount = random.choices(list(sample_loan_amounts_prob.keys()), weights=sample_loan_amounts_prob.values(), k=n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cac\n",
    "print(\"The orginal loan amount mean is\", df[\"loan_amount\"].mean())\n",
    "print (\"The Sample data loan amount mean is \",sum(sample_loan_amount)/len(sample_loan_amount) )#havent created dataframe yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add new sample Data to my Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add my new sample data to my data frame\n",
    "sample_df = pd.DataFrame({'sample_age':sample_age ,\n",
    "                   'sample_loan_purpose':sample_loan_purpose ,\n",
    "                   'sample_gender': sample_gender ,\n",
    "                          'sample_loan_amount':sample_loan_amount\n",
    "                  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display by new sample dataframe\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(sample_df,hue =\"sample_loan_purpose\");\n",
    "#sns.pairplot(df,x_vars = \"age\",y_vars=\"loan_amount\",hue =\"loan_purpose\");\n",
    "#Sample_Loan_Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(sample_df.corr(),annot= True); #insert link here from medium that i used fro below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using seaborn boxplot with x and y variables to visuale relationship between age and loan purpose\n",
    "sns.catplot(x=\"sample_loan_purpose\", y=\"sample_age\", hue=\"sample_gender\", kind=\"box\", data=sample_df);\n",
    "#https://seaborn.pydata.org/tutorial/categorical.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the style of the countplot\n",
    "sns.set(style=\"darkgrid\")\n",
    "#generate a countplot of loan purpose\n",
    "sns.countplot(x='sample_loan_purpose',hue=\"sample_gender\" , data=sample_df)\n",
    "#show the title\n",
    "plt.title (\"Sample Loan Purpose by Gender Profile\")\n",
    "#plot the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='predictions'></a>\n",
    "### Try Some Predictions using Sklearn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scale = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sample_df[['sample_age','sample_loan_amount']]\n",
    "scaledx = scale.fit_transform(X)\n",
    "#print(scaledx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[['month_number']]\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(scaledx, y)\n",
    "scaled = scale.transform([[20,8]])\n",
    "predicted_month = regr.predict([scaled[0]])\n",
    "print(predicted_month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model and Train?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Digging a bit futher - summary by years "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.Age.plot(kind='kde');\n",
    "#df.groupby('Gender').Age.plot(kind='kde')\n",
    "#df.Age.plot(kind='kde')\n",
    "\n",
    "\n",
    "#Random_Age = np.random.randint(19, 89, n_samples)\n",
    "#Random_Age = np.random.normal(45.241362,15.595089,n_samples).astype(int)\n",
    "#Random_Age = np.random.rayleigh(45.241362,n_samples).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "#sns.distplot(Age);\n",
    "#df.groupby(\"Age\").Loan.count()\n",
    "#df.count([\"Loan Purpose\"])\n",
    "#test = df['Loan Purpose'].count\n",
    "#test\n",
    "\n",
    "\n",
    "#df.Age.plot(kind='kde');\n",
    "#df.groupby('Gender').Age.plot(kind='kde')\n",
    "#df.Age.plot(kind='kde')\n",
    "#Loan Amount = df[\"Loan Amount\"]\n",
    "\n",
    "\n",
    "\n",
    "#rng.permutation(sample_df)\n",
    "\n",
    "\n",
    "\n",
    "#create some random varibales just for testing at the minute\n",
    "#researched https://www.delftstack.com/howto/python-pandas/how-to-randomly-shuffle-dataframe-rows-in-pandas/\n",
    "#Loan_Types = (\"Personal\", \"Car\", \"Agri\", \"Student\",\"Home\" )\n",
    "\n",
    "\n",
    "#new_date = df['date_application2']\n",
    "#df['date_application2'] = pd.to_datetime(df['date_application'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conclusion'></a>\n",
    "## Project Conclusion and Summary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='research'></a>\n",
    "## Research undertaken and links to relevant sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
